{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting transformer-lens\n",
      "  Downloading transformer_lens-1.7.0-py3-none-any.whl (114 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m114.3/114.3 kB\u001b[0m \u001b[31m4.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting nvidia-nvtx-cu12==12.1.105\n",
      "  Downloading nvidia_nvtx_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (99 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m99.1/99.1 kB\u001b[0m \u001b[31m8.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting accelerate>=0.23.0\n",
      "  Downloading accelerate-0.23.0-py3-none-any.whl (258 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m258.1/258.1 kB\u001b[0m \u001b[31m13.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting nvidia-curand-cu12==10.3.2.106\n",
      "  Downloading nvidia_curand_cu12-10.3.2.106-py3-none-manylinux1_x86_64.whl (56.5 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.5/56.5 MB\u001b[0m \u001b[31m15.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hCollecting einops>=0.6.0\n",
      "  Downloading einops-0.7.0-py3-none-any.whl (44 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m44.6/44.6 kB\u001b[0m \u001b[31m6.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting rich>=12.6.0\n",
      "  Downloading rich-13.6.0-py3-none-any.whl (239 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m239.8/239.8 kB\u001b[0m \u001b[31m13.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting transformers>=4.25.1\n",
      "  Downloading transformers-4.34.0-py3-none-any.whl (7.7 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.7/7.7 MB\u001b[0m \u001b[31m20.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hCollecting fancy-einsum>=0.0.3\n",
      "  Using cached fancy_einsum-0.0.3-py3-none-any.whl (6.2 kB)\n",
      "Collecting triton==2.1.0\n",
      "  Downloading triton-2.1.0-0-cp39-cp39-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (89.3 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m89.3/89.3 MB\u001b[0m \u001b[31m13.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hCollecting nvidia-cuda-cupti-cu12==12.1.105\n",
      "  Downloading nvidia_cuda_cupti_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (14.1 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m14.1/14.1 MB\u001b[0m \u001b[31m22.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hCollecting jaxtyping>=0.2.11\n",
      "  Downloading jaxtyping-0.2.23-py3-none-any.whl (29 kB)\n",
      "Collecting datasets>=2.7.1\n",
      "  Downloading datasets-2.14.5-py3-none-any.whl (519 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m519.6/519.6 kB\u001b[0m \u001b[31m18.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting beartype<0.15.0,>=0.14.1\n",
      "  Downloading beartype-0.14.1-py3-none-any.whl (739 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m739.7/739.7 kB\u001b[0m \u001b[31m23.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting nvidia-cuda-nvrtc-cu12==12.1.105\n",
      "  Downloading nvidia_cuda_nvrtc_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (23.7 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m23.7/23.7 MB\u001b[0m \u001b[31m19.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hCollecting nvidia-cufft-cu12==11.0.2.54\n",
      "  Downloading nvidia_cufft_cu12-11.0.2.54-py3-none-manylinux1_x86_64.whl (121.6 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m121.6/121.6 MB\u001b[0m \u001b[31m11.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hCollecting wandb>=0.13.5\n",
      "  Downloading wandb-0.15.12-py3-none-any.whl (2.1 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.1/2.1 MB\u001b[0m \u001b[31m20.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hCollecting nvidia-cusparse-cu12==12.1.0.106\n",
      "  Downloading nvidia_cusparse_cu12-12.1.0.106-py3-none-manylinux1_x86_64.whl (196.0 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m196.0/196.0 MB\u001b[0m \u001b[31m7.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: pandas>=1.1.5 in /home/coco/anaconda3/lib/python3.9/site-packages (from transformer-lens) (1.4.4)\n",
      "Collecting nvidia-cublas-cu12==12.1.3.1\n",
      "  Downloading nvidia_cublas_cu12-12.1.3.1-py3-none-manylinux1_x86_64.whl (410.6 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m410.6/410.6 MB\u001b[0m \u001b[31m5.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: numpy>=1.21 in /home/coco/anaconda3/lib/python3.9/site-packages (from transformer-lens) (1.21.5)\n",
      "Collecting nvidia-cudnn-cu12==8.9.2.26\n",
      "  Downloading nvidia_cudnn_cu12-8.9.2.26-py3-none-manylinux1_x86_64.whl (731.7 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m731.7/731.7 MB\u001b[0m \u001b[31m3.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hCollecting nvidia-nccl-cu12==2.18.1\n",
      "  Downloading nvidia_nccl_cu12-2.18.1-py3-none-manylinux1_x86_64.whl (209.8 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m209.8/209.8 MB\u001b[0m \u001b[31m8.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: typing-extensions in /home/coco/anaconda3/lib/python3.9/site-packages (from transformer-lens) (4.3.0)\n",
      "Collecting torch>=1.10\n",
      "  Downloading torch-2.1.0-cp39-cp39-manylinux1_x86_64.whl (670.2 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m670.2/670.2 MB\u001b[0m \u001b[31m3.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hCollecting nvidia-cuda-runtime-cu12==12.1.105\n",
      "  Downloading nvidia_cuda_runtime_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (823 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m823.6/823.6 kB\u001b[0m \u001b[31m34.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting nvidia-cusolver-cu12==11.4.5.107\n",
      "  Downloading nvidia_cusolver_cu12-11.4.5.107-py3-none-manylinux1_x86_64.whl (124.2 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m124.2/124.2 MB\u001b[0m \u001b[31m11.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: tqdm>=4.64.1 in /home/coco/anaconda3/lib/python3.9/site-packages (from transformer-lens) (4.64.1)\n",
      "Collecting nvidia-nvjitlink-cu12\n",
      "  Downloading nvidia_nvjitlink_cu12-12.2.140-py3-none-manylinux1_x86_64.whl (20.2 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m20.2/20.2 MB\u001b[0m \u001b[31m19.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: filelock in /home/coco/anaconda3/lib/python3.9/site-packages (from triton==2.1.0->transformer-lens) (3.6.0)\n",
      "Requirement already satisfied: pyyaml in /home/coco/anaconda3/lib/python3.9/site-packages (from accelerate>=0.23.0->transformer-lens) (6.0)\n",
      "Collecting huggingface-hub\n",
      "  Downloading huggingface_hub-0.18.0-py3-none-any.whl (301 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m302.0/302.0 kB\u001b[0m \u001b[31m17.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: psutil in /home/coco/anaconda3/lib/python3.9/site-packages (from accelerate>=0.23.0->transformer-lens) (5.9.0)\n",
      "Requirement already satisfied: packaging>=20.0 in /home/coco/anaconda3/lib/python3.9/site-packages (from accelerate>=0.23.0->transformer-lens) (21.3)\n",
      "Collecting aiohttp\n",
      "  Downloading aiohttp-3.8.6-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.1 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m20.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hCollecting pyarrow>=8.0.0\n",
      "  Downloading pyarrow-13.0.0-cp39-cp39-manylinux_2_28_x86_64.whl (40.1 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m40.1/40.1 MB\u001b[0m \u001b[31m17.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hCollecting multiprocess\n",
      "  Downloading multiprocess-0.70.15-py39-none-any.whl (133 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m133.3/133.3 kB\u001b[0m \u001b[31m10.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting fsspec[http]<2023.9.0,>=2023.1.0\n",
      "  Downloading fsspec-2023.6.0-py3-none-any.whl (163 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m163.8/163.8 kB\u001b[0m \u001b[31m13.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: dill<0.3.8,>=0.3.0 in /home/coco/anaconda3/lib/python3.9/site-packages (from datasets>=2.7.1->transformer-lens) (0.3.4)\n",
      "Collecting xxhash\n",
      "  Downloading xxhash-3.4.1-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (193 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m193.8/193.8 kB\u001b[0m \u001b[31m19.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: requests>=2.19.0 in /home/coco/anaconda3/lib/python3.9/site-packages (from datasets>=2.7.1->transformer-lens) (2.28.1)\n",
      "Collecting typeguard<3,>=2.13.3\n",
      "  Downloading typeguard-2.13.3-py3-none-any.whl (17 kB)\n",
      "Requirement already satisfied: python-dateutil>=2.8.1 in /home/coco/anaconda3/lib/python3.9/site-packages (from pandas>=1.1.5->transformer-lens) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in /home/coco/anaconda3/lib/python3.9/site-packages (from pandas>=1.1.5->transformer-lens) (2022.1)\n",
      "Collecting markdown-it-py>=2.2.0\n",
      "  Downloading markdown_it_py-3.0.0-py3-none-any.whl (87 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m87.5/87.5 kB\u001b[0m \u001b[31m8.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting pygments<3.0.0,>=2.13.0\n",
      "  Downloading Pygments-2.16.1-py3-none-any.whl (1.2 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.2/1.2 MB\u001b[0m \u001b[31m21.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: fsspec in /home/coco/anaconda3/lib/python3.9/site-packages (from torch>=1.10->transformer-lens) (2022.7.1)\n",
      "Requirement already satisfied: sympy in /home/coco/anaconda3/lib/python3.9/site-packages (from torch>=1.10->transformer-lens) (1.10.1)\n",
      "Requirement already satisfied: jinja2 in /home/coco/anaconda3/lib/python3.9/site-packages (from torch>=1.10->transformer-lens) (2.11.3)\n",
      "Requirement already satisfied: networkx in /home/coco/anaconda3/lib/python3.9/site-packages (from torch>=1.10->transformer-lens) (2.8.4)\n",
      "Collecting safetensors>=0.3.1\n",
      "  Downloading safetensors-0.4.0-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.3 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m14.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hCollecting tokenizers<0.15,>=0.14\n",
      "  Downloading tokenizers-0.14.1-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.8 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.8/3.8 MB\u001b[0m \u001b[31m20.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: regex!=2019.12.17 in /home/coco/anaconda3/lib/python3.9/site-packages (from transformers>=4.25.1->transformer-lens) (2022.7.9)\n",
      "Requirement already satisfied: Click!=8.0.0,>=7.1 in /home/coco/anaconda3/lib/python3.9/site-packages (from wandb>=0.13.5->transformer-lens) (8.0.4)\n",
      "Requirement already satisfied: setuptools in /home/coco/anaconda3/lib/python3.9/site-packages (from wandb>=0.13.5->transformer-lens) (63.4.1)\n",
      "Collecting docker-pycreds>=0.4.0\n",
      "  Using cached docker_pycreds-0.4.0-py2.py3-none-any.whl (9.0 kB)\n",
      "Collecting pathtools\n",
      "  Using cached pathtools-0.1.2.tar.gz (11 kB)\n",
      "  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hCollecting setproctitle\n",
      "  Downloading setproctitle-1.3.3-cp39-cp39-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (30 kB)\n",
      "Collecting sentry-sdk>=1.0.0\n",
      "  Downloading sentry_sdk-1.32.0-py2.py3-none-any.whl (240 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m241.0/241.0 kB\u001b[0m \u001b[31m17.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting protobuf!=4.21.0,<5,>=3.15.0\n",
      "  Downloading protobuf-4.24.4-cp37-abi3-manylinux2014_x86_64.whl (311 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m311.6/311.6 kB\u001b[0m \u001b[31m17.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting GitPython!=3.1.29,>=1.0.0\n",
      "  Downloading GitPython-3.1.38-py3-none-any.whl (190 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m190.6/190.6 kB\u001b[0m \u001b[31m15.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: appdirs>=1.4.3 in /home/coco/anaconda3/lib/python3.9/site-packages (from wandb>=0.13.5->transformer-lens) (1.4.4)\n",
      "Requirement already satisfied: six>=1.4.0 in /home/coco/anaconda3/lib/python3.9/site-packages (from docker-pycreds>=0.4.0->wandb>=0.13.5->transformer-lens) (1.16.0)\n",
      "Collecting aiosignal>=1.1.2\n",
      "  Using cached aiosignal-1.3.1-py3-none-any.whl (7.6 kB)\n",
      "Requirement already satisfied: charset-normalizer<4.0,>=2.0 in /home/coco/anaconda3/lib/python3.9/site-packages (from aiohttp->datasets>=2.7.1->transformer-lens) (2.0.4)\n",
      "Collecting frozenlist>=1.1.1\n",
      "  Downloading frozenlist-1.4.0-cp39-cp39-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (228 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m228.0/228.0 kB\u001b[0m \u001b[31m18.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting yarl<2.0,>=1.0\n",
      "  Downloading yarl-1.9.2-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (269 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m269.4/269.4 kB\u001b[0m \u001b[31m15.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting multidict<7.0,>=4.5\n",
      "  Downloading multidict-6.0.4-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (114 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m114.2/114.2 kB\u001b[0m \u001b[31m9.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: attrs>=17.3.0 in /home/coco/anaconda3/lib/python3.9/site-packages (from aiohttp->datasets>=2.7.1->transformer-lens) (21.4.0)\n",
      "Collecting async-timeout<5.0,>=4.0.0a3\n",
      "  Downloading async_timeout-4.0.3-py3-none-any.whl (5.7 kB)\n",
      "Collecting gitdb<5,>=4.0.1\n",
      "  Using cached gitdb-4.0.10-py3-none-any.whl (62 kB)\n",
      "Collecting mdurl~=0.1\n",
      "  Using cached mdurl-0.1.2-py3-none-any.whl (10.0 kB)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /home/coco/anaconda3/lib/python3.9/site-packages (from packaging>=20.0->accelerate>=0.23.0->transformer-lens) (3.0.9)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/coco/anaconda3/lib/python3.9/site-packages (from requests>=2.19.0->datasets>=2.7.1->transformer-lens) (2022.9.14)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /home/coco/anaconda3/lib/python3.9/site-packages (from requests>=2.19.0->datasets>=2.7.1->transformer-lens) (1.26.11)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/coco/anaconda3/lib/python3.9/site-packages (from requests>=2.19.0->datasets>=2.7.1->transformer-lens) (3.3)\n",
      "Collecting huggingface-hub\n",
      "  Downloading huggingface_hub-0.17.3-py3-none-any.whl (295 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m295.0/295.0 kB\u001b[0m \u001b[31m20.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: MarkupSafe>=0.23 in /home/coco/anaconda3/lib/python3.9/site-packages (from jinja2->torch>=1.10->transformer-lens) (2.0.1)\n",
      "Collecting dill<0.3.8,>=0.3.0\n",
      "  Downloading dill-0.3.7-py3-none-any.whl (115 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m115.3/115.3 kB\u001b[0m \u001b[31m14.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: mpmath>=0.19 in /home/coco/anaconda3/lib/python3.9/site-packages (from sympy->torch>=1.10->transformer-lens) (1.2.1)\n",
      "Collecting smmap<6,>=3.0.1\n",
      "  Downloading smmap-5.0.1-py3-none-any.whl (24 kB)\n",
      "Building wheels for collected packages: pathtools\n",
      "  Building wheel for pathtools (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for pathtools: filename=pathtools-0.1.2-py3-none-any.whl size=8792 sha256=4ea49afcd4ea8291a09ae437c31c6fa9b379ef82a138d9047322e6b82db0f893\n",
      "  Stored in directory: /home/coco/.cache/pip/wheels/b7/0a/67/ada2a22079218c75a88361c0782855cc72aebc4d18d0289d05\n",
      "Successfully built pathtools\n",
      "Installing collected packages: pathtools, xxhash, typeguard, triton, smmap, setproctitle, sentry-sdk, safetensors, pygments, pyarrow, protobuf, nvidia-nvtx-cu12, nvidia-nvjitlink-cu12, nvidia-nccl-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, multidict, mdurl, fsspec, frozenlist, fancy-einsum, einops, docker-pycreds, dill, beartype, async-timeout, yarl, nvidia-cusparse-cu12, nvidia-cudnn-cu12, multiprocess, markdown-it-py, jaxtyping, huggingface-hub, gitdb, aiosignal, tokenizers, rich, nvidia-cusolver-cu12, GitPython, aiohttp, wandb, transformers, torch, datasets, accelerate, transformer-lens\n",
      "  Attempting uninstall: pygments\n",
      "    Found existing installation: Pygments 2.11.2\n",
      "    Uninstalling Pygments-2.11.2:\n",
      "      Successfully uninstalled Pygments-2.11.2\n",
      "  Attempting uninstall: fsspec\n",
      "    Found existing installation: fsspec 2022.7.1\n",
      "    Uninstalling fsspec-2022.7.1:\n",
      "      Successfully uninstalled fsspec-2022.7.1\n",
      "  Attempting uninstall: dill\n",
      "    Found existing installation: dill 0.3.4\n",
      "    Uninstalling dill-0.3.4:\n",
      "      Successfully uninstalled dill-0.3.4\n",
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "spyder 5.3.3 requires pyqt5<5.16, which is not installed.\n",
      "spyder 5.3.3 requires pyqtwebengine<5.16, which is not installed.\u001b[0m\u001b[31m\n",
      "\u001b[0mSuccessfully installed GitPython-3.1.38 accelerate-0.23.0 aiohttp-3.8.6 aiosignal-1.3.1 async-timeout-4.0.3 beartype-0.14.1 datasets-2.14.5 dill-0.3.7 docker-pycreds-0.4.0 einops-0.7.0 fancy-einsum-0.0.3 frozenlist-1.4.0 fsspec-2023.6.0 gitdb-4.0.10 huggingface-hub-0.17.3 jaxtyping-0.2.23 markdown-it-py-3.0.0 mdurl-0.1.2 multidict-6.0.4 multiprocess-0.70.15 nvidia-cublas-cu12-12.1.3.1 nvidia-cuda-cupti-cu12-12.1.105 nvidia-cuda-nvrtc-cu12-12.1.105 nvidia-cuda-runtime-cu12-12.1.105 nvidia-cudnn-cu12-8.9.2.26 nvidia-cufft-cu12-11.0.2.54 nvidia-curand-cu12-10.3.2.106 nvidia-cusolver-cu12-11.4.5.107 nvidia-cusparse-cu12-12.1.0.106 nvidia-nccl-cu12-2.18.1 nvidia-nvjitlink-cu12-12.2.140 nvidia-nvtx-cu12-12.1.105 pathtools-0.1.2 protobuf-4.24.4 pyarrow-13.0.0 pygments-2.16.1 rich-13.6.0 safetensors-0.4.0 sentry-sdk-1.32.0 setproctitle-1.3.3 smmap-5.0.1 tokenizers-0.14.1 torch-2.1.0 transformer-lens-1.7.0 transformers-4.34.0 triton-2.1.0 typeguard-2.13.3 wandb-0.15.12 xxhash-3.4.1 yarl-1.9.2\n"
     ]
    }
   ],
   "source": [
    "! pip install transformer-lens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using pad_token, but it is not set yet.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded pretrained model gpt2-small into HookedTransformer\n"
     ]
    }
   ],
   "source": [
    "from transformer_lens import HookedTransformer, utils\n",
    "\n",
    "model = HookedTransformer.from_pretrained(\"gpt2-small\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logits dims: torch.Size([1, 6, 50257]) [batch, position, vocab]\n",
      "Next word prediction:  Turing\n"
     ]
    }
   ],
   "source": [
    "logits = model(\"Famous computer scientist Alan\")\n",
    "\n",
    "# Logit dims\n",
    "print(\"Logits dims:\", logits.shape, \"[batch, position, vocab]\")\n",
    "\n",
    "# Logits (raw preds from the model)\n",
    "next_token_logits = logits[0, -1]\n",
    "next_token_prediction = next_token_logits.argmax()\n",
    "next_word_prediction = model.tokenizer.decode(next_token_prediction)\n",
    "\n",
    "print('Next word prediction:', next_word_prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hook_embed torch.Size([1, 6, 768])\n",
      "hook_pos_embed torch.Size([1, 6, 768])\n",
      "blocks.0.hook_resid_pre torch.Size([1, 6, 768])\n",
      "blocks.0.ln1.hook_scale torch.Size([1, 6, 1])\n",
      "blocks.0.ln1.hook_normalized torch.Size([1, 6, 768])\n",
      "blocks.0.attn.hook_q torch.Size([1, 6, 12, 64])\n",
      "blocks.0.attn.hook_k torch.Size([1, 6, 12, 64])\n",
      "blocks.0.attn.hook_v torch.Size([1, 6, 12, 64])\n",
      "blocks.0.attn.hook_attn_scores torch.Size([1, 12, 6, 6])\n",
      "blocks.0.attn.hook_pattern torch.Size([1, 12, 6, 6])\n",
      "blocks.0.attn.hook_z torch.Size([1, 6, 12, 64])\n",
      "blocks.0.hook_attn_out torch.Size([1, 6, 768])\n",
      "blocks.0.hook_resid_mid torch.Size([1, 6, 768])\n",
      "blocks.0.ln2.hook_scale torch.Size([1, 6, 1])\n",
      "blocks.0.ln2.hook_normalized torch.Size([1, 6, 768])\n",
      "blocks.0.mlp.hook_pre torch.Size([1, 6, 3072])\n",
      "blocks.0.mlp.hook_post torch.Size([1, 6, 3072])\n",
      "blocks.0.hook_mlp_out torch.Size([1, 6, 768])\n",
      "blocks.0.hook_resid_post torch.Size([1, 6, 768])\n",
      "blocks.1.hook_resid_pre torch.Size([1, 6, 768])\n",
      "blocks.1.ln1.hook_scale torch.Size([1, 6, 1])\n",
      "blocks.1.ln1.hook_normalized torch.Size([1, 6, 768])\n",
      "blocks.1.attn.hook_q torch.Size([1, 6, 12, 64])\n",
      "blocks.1.attn.hook_k torch.Size([1, 6, 12, 64])\n",
      "blocks.1.attn.hook_v torch.Size([1, 6, 12, 64])\n",
      "blocks.1.attn.hook_attn_scores torch.Size([1, 12, 6, 6])\n",
      "blocks.1.attn.hook_pattern torch.Size([1, 12, 6, 6])\n",
      "blocks.1.attn.hook_z torch.Size([1, 6, 12, 64])\n",
      "blocks.1.hook_attn_out torch.Size([1, 6, 768])\n",
      "blocks.1.hook_resid_mid torch.Size([1, 6, 768])\n",
      "blocks.1.ln2.hook_scale torch.Size([1, 6, 1])\n",
      "blocks.1.ln2.hook_normalized torch.Size([1, 6, 768])\n",
      "blocks.1.mlp.hook_pre torch.Size([1, 6, 3072])\n",
      "blocks.1.mlp.hook_post torch.Size([1, 6, 3072])\n",
      "blocks.1.hook_mlp_out torch.Size([1, 6, 768])\n",
      "blocks.1.hook_resid_post torch.Size([1, 6, 768])\n",
      "blocks.2.hook_resid_pre torch.Size([1, 6, 768])\n",
      "blocks.2.ln1.hook_scale torch.Size([1, 6, 1])\n",
      "blocks.2.ln1.hook_normalized torch.Size([1, 6, 768])\n",
      "blocks.2.attn.hook_q torch.Size([1, 6, 12, 64])\n",
      "blocks.2.attn.hook_k torch.Size([1, 6, 12, 64])\n",
      "blocks.2.attn.hook_v torch.Size([1, 6, 12, 64])\n",
      "blocks.2.attn.hook_attn_scores torch.Size([1, 12, 6, 6])\n",
      "blocks.2.attn.hook_pattern torch.Size([1, 12, 6, 6])\n",
      "blocks.2.attn.hook_z torch.Size([1, 6, 12, 64])\n",
      "blocks.2.hook_attn_out torch.Size([1, 6, 768])\n",
      "blocks.2.hook_resid_mid torch.Size([1, 6, 768])\n",
      "blocks.2.ln2.hook_scale torch.Size([1, 6, 1])\n",
      "blocks.2.ln2.hook_normalized torch.Size([1, 6, 768])\n",
      "blocks.2.mlp.hook_pre torch.Size([1, 6, 3072])\n",
      "blocks.2.mlp.hook_post torch.Size([1, 6, 3072])\n",
      "blocks.2.hook_mlp_out torch.Size([1, 6, 768])\n",
      "blocks.2.hook_resid_post torch.Size([1, 6, 768])\n",
      "blocks.3.hook_resid_pre torch.Size([1, 6, 768])\n",
      "blocks.3.ln1.hook_scale torch.Size([1, 6, 1])\n",
      "blocks.3.ln1.hook_normalized torch.Size([1, 6, 768])\n",
      "blocks.3.attn.hook_q torch.Size([1, 6, 12, 64])\n",
      "blocks.3.attn.hook_k torch.Size([1, 6, 12, 64])\n",
      "blocks.3.attn.hook_v torch.Size([1, 6, 12, 64])\n",
      "blocks.3.attn.hook_attn_scores torch.Size([1, 12, 6, 6])\n",
      "blocks.3.attn.hook_pattern torch.Size([1, 12, 6, 6])\n",
      "blocks.3.attn.hook_z torch.Size([1, 6, 12, 64])\n",
      "blocks.3.hook_attn_out torch.Size([1, 6, 768])\n",
      "blocks.3.hook_resid_mid torch.Size([1, 6, 768])\n",
      "blocks.3.ln2.hook_scale torch.Size([1, 6, 1])\n",
      "blocks.3.ln2.hook_normalized torch.Size([1, 6, 768])\n",
      "blocks.3.mlp.hook_pre torch.Size([1, 6, 3072])\n",
      "blocks.3.mlp.hook_post torch.Size([1, 6, 3072])\n",
      "blocks.3.hook_mlp_out torch.Size([1, 6, 768])\n",
      "blocks.3.hook_resid_post torch.Size([1, 6, 768])\n",
      "blocks.4.hook_resid_pre torch.Size([1, 6, 768])\n",
      "blocks.4.ln1.hook_scale torch.Size([1, 6, 1])\n",
      "blocks.4.ln1.hook_normalized torch.Size([1, 6, 768])\n",
      "blocks.4.attn.hook_q torch.Size([1, 6, 12, 64])\n",
      "blocks.4.attn.hook_k torch.Size([1, 6, 12, 64])\n",
      "blocks.4.attn.hook_v torch.Size([1, 6, 12, 64])\n",
      "blocks.4.attn.hook_attn_scores torch.Size([1, 12, 6, 6])\n",
      "blocks.4.attn.hook_pattern torch.Size([1, 12, 6, 6])\n",
      "blocks.4.attn.hook_z torch.Size([1, 6, 12, 64])\n",
      "blocks.4.hook_attn_out torch.Size([1, 6, 768])\n",
      "blocks.4.hook_resid_mid torch.Size([1, 6, 768])\n",
      "blocks.4.ln2.hook_scale torch.Size([1, 6, 1])\n",
      "blocks.4.ln2.hook_normalized torch.Size([1, 6, 768])\n",
      "blocks.4.mlp.hook_pre torch.Size([1, 6, 3072])\n",
      "blocks.4.mlp.hook_post torch.Size([1, 6, 3072])\n",
      "blocks.4.hook_mlp_out torch.Size([1, 6, 768])\n",
      "blocks.4.hook_resid_post torch.Size([1, 6, 768])\n",
      "blocks.5.hook_resid_pre torch.Size([1, 6, 768])\n",
      "blocks.5.ln1.hook_scale torch.Size([1, 6, 1])\n",
      "blocks.5.ln1.hook_normalized torch.Size([1, 6, 768])\n",
      "blocks.5.attn.hook_q torch.Size([1, 6, 12, 64])\n",
      "blocks.5.attn.hook_k torch.Size([1, 6, 12, 64])\n",
      "blocks.5.attn.hook_v torch.Size([1, 6, 12, 64])\n",
      "blocks.5.attn.hook_attn_scores torch.Size([1, 12, 6, 6])\n",
      "blocks.5.attn.hook_pattern torch.Size([1, 12, 6, 6])\n",
      "blocks.5.attn.hook_z torch.Size([1, 6, 12, 64])\n",
      "blocks.5.hook_attn_out torch.Size([1, 6, 768])\n",
      "blocks.5.hook_resid_mid torch.Size([1, 6, 768])\n",
      "blocks.5.ln2.hook_scale torch.Size([1, 6, 1])\n",
      "blocks.5.ln2.hook_normalized torch.Size([1, 6, 768])\n",
      "blocks.5.mlp.hook_pre torch.Size([1, 6, 3072])\n",
      "blocks.5.mlp.hook_post torch.Size([1, 6, 3072])\n",
      "blocks.5.hook_mlp_out torch.Size([1, 6, 768])\n",
      "blocks.5.hook_resid_post torch.Size([1, 6, 768])\n",
      "blocks.6.hook_resid_pre torch.Size([1, 6, 768])\n",
      "blocks.6.ln1.hook_scale torch.Size([1, 6, 1])\n",
      "blocks.6.ln1.hook_normalized torch.Size([1, 6, 768])\n",
      "blocks.6.attn.hook_q torch.Size([1, 6, 12, 64])\n",
      "blocks.6.attn.hook_k torch.Size([1, 6, 12, 64])\n",
      "blocks.6.attn.hook_v torch.Size([1, 6, 12, 64])\n",
      "blocks.6.attn.hook_attn_scores torch.Size([1, 12, 6, 6])\n",
      "blocks.6.attn.hook_pattern torch.Size([1, 12, 6, 6])\n",
      "blocks.6.attn.hook_z torch.Size([1, 6, 12, 64])\n",
      "blocks.6.hook_attn_out torch.Size([1, 6, 768])\n",
      "blocks.6.hook_resid_mid torch.Size([1, 6, 768])\n",
      "blocks.6.ln2.hook_scale torch.Size([1, 6, 1])\n",
      "blocks.6.ln2.hook_normalized torch.Size([1, 6, 768])\n",
      "blocks.6.mlp.hook_pre torch.Size([1, 6, 3072])\n",
      "blocks.6.mlp.hook_post torch.Size([1, 6, 3072])\n",
      "blocks.6.hook_mlp_out torch.Size([1, 6, 768])\n",
      "blocks.6.hook_resid_post torch.Size([1, 6, 768])\n",
      "blocks.7.hook_resid_pre torch.Size([1, 6, 768])\n",
      "blocks.7.ln1.hook_scale torch.Size([1, 6, 1])\n",
      "blocks.7.ln1.hook_normalized torch.Size([1, 6, 768])\n",
      "blocks.7.attn.hook_q torch.Size([1, 6, 12, 64])\n",
      "blocks.7.attn.hook_k torch.Size([1, 6, 12, 64])\n",
      "blocks.7.attn.hook_v torch.Size([1, 6, 12, 64])\n",
      "blocks.7.attn.hook_attn_scores torch.Size([1, 12, 6, 6])\n",
      "blocks.7.attn.hook_pattern torch.Size([1, 12, 6, 6])\n",
      "blocks.7.attn.hook_z torch.Size([1, 6, 12, 64])\n",
      "blocks.7.hook_attn_out torch.Size([1, 6, 768])\n",
      "blocks.7.hook_resid_mid torch.Size([1, 6, 768])\n",
      "blocks.7.ln2.hook_scale torch.Size([1, 6, 1])\n",
      "blocks.7.ln2.hook_normalized torch.Size([1, 6, 768])\n",
      "blocks.7.mlp.hook_pre torch.Size([1, 6, 3072])\n",
      "blocks.7.mlp.hook_post torch.Size([1, 6, 3072])\n",
      "blocks.7.hook_mlp_out torch.Size([1, 6, 768])\n",
      "blocks.7.hook_resid_post torch.Size([1, 6, 768])\n",
      "blocks.8.hook_resid_pre torch.Size([1, 6, 768])\n",
      "blocks.8.ln1.hook_scale torch.Size([1, 6, 1])\n",
      "blocks.8.ln1.hook_normalized torch.Size([1, 6, 768])\n",
      "blocks.8.attn.hook_q torch.Size([1, 6, 12, 64])\n",
      "blocks.8.attn.hook_k torch.Size([1, 6, 12, 64])\n",
      "blocks.8.attn.hook_v torch.Size([1, 6, 12, 64])\n",
      "blocks.8.attn.hook_attn_scores torch.Size([1, 12, 6, 6])\n",
      "blocks.8.attn.hook_pattern torch.Size([1, 12, 6, 6])\n",
      "blocks.8.attn.hook_z torch.Size([1, 6, 12, 64])\n",
      "blocks.8.hook_attn_out torch.Size([1, 6, 768])\n",
      "blocks.8.hook_resid_mid torch.Size([1, 6, 768])\n",
      "blocks.8.ln2.hook_scale torch.Size([1, 6, 1])\n",
      "blocks.8.ln2.hook_normalized torch.Size([1, 6, 768])\n",
      "blocks.8.mlp.hook_pre torch.Size([1, 6, 3072])\n",
      "blocks.8.mlp.hook_post torch.Size([1, 6, 3072])\n",
      "blocks.8.hook_mlp_out torch.Size([1, 6, 768])\n",
      "blocks.8.hook_resid_post torch.Size([1, 6, 768])\n",
      "blocks.9.hook_resid_pre torch.Size([1, 6, 768])\n",
      "blocks.9.ln1.hook_scale torch.Size([1, 6, 1])\n",
      "blocks.9.ln1.hook_normalized torch.Size([1, 6, 768])\n",
      "blocks.9.attn.hook_q torch.Size([1, 6, 12, 64])\n",
      "blocks.9.attn.hook_k torch.Size([1, 6, 12, 64])\n",
      "blocks.9.attn.hook_v torch.Size([1, 6, 12, 64])\n",
      "blocks.9.attn.hook_attn_scores torch.Size([1, 12, 6, 6])\n",
      "blocks.9.attn.hook_pattern torch.Size([1, 12, 6, 6])\n",
      "blocks.9.attn.hook_z torch.Size([1, 6, 12, 64])\n",
      "blocks.9.hook_attn_out torch.Size([1, 6, 768])\n",
      "blocks.9.hook_resid_mid torch.Size([1, 6, 768])\n",
      "blocks.9.ln2.hook_scale torch.Size([1, 6, 1])\n",
      "blocks.9.ln2.hook_normalized torch.Size([1, 6, 768])\n",
      "blocks.9.mlp.hook_pre torch.Size([1, 6, 3072])\n",
      "blocks.9.mlp.hook_post torch.Size([1, 6, 3072])\n",
      "blocks.9.hook_mlp_out torch.Size([1, 6, 768])\n",
      "blocks.9.hook_resid_post torch.Size([1, 6, 768])\n",
      "blocks.10.hook_resid_pre torch.Size([1, 6, 768])\n",
      "blocks.10.ln1.hook_scale torch.Size([1, 6, 1])\n",
      "blocks.10.ln1.hook_normalized torch.Size([1, 6, 768])\n",
      "blocks.10.attn.hook_q torch.Size([1, 6, 12, 64])\n",
      "blocks.10.attn.hook_k torch.Size([1, 6, 12, 64])\n",
      "blocks.10.attn.hook_v torch.Size([1, 6, 12, 64])\n",
      "blocks.10.attn.hook_attn_scores torch.Size([1, 12, 6, 6])\n",
      "blocks.10.attn.hook_pattern torch.Size([1, 12, 6, 6])\n",
      "blocks.10.attn.hook_z torch.Size([1, 6, 12, 64])\n",
      "blocks.10.hook_attn_out torch.Size([1, 6, 768])\n",
      "blocks.10.hook_resid_mid torch.Size([1, 6, 768])\n",
      "blocks.10.ln2.hook_scale torch.Size([1, 6, 1])\n",
      "blocks.10.ln2.hook_normalized torch.Size([1, 6, 768])\n",
      "blocks.10.mlp.hook_pre torch.Size([1, 6, 3072])\n",
      "blocks.10.mlp.hook_post torch.Size([1, 6, 3072])\n",
      "blocks.10.hook_mlp_out torch.Size([1, 6, 768])\n",
      "blocks.10.hook_resid_post torch.Size([1, 6, 768])\n",
      "blocks.11.hook_resid_pre torch.Size([1, 6, 768])\n",
      "blocks.11.ln1.hook_scale torch.Size([1, 6, 1])\n",
      "blocks.11.ln1.hook_normalized torch.Size([1, 6, 768])\n",
      "blocks.11.attn.hook_q torch.Size([1, 6, 12, 64])\n",
      "blocks.11.attn.hook_k torch.Size([1, 6, 12, 64])\n",
      "blocks.11.attn.hook_v torch.Size([1, 6, 12, 64])\n",
      "blocks.11.attn.hook_attn_scores torch.Size([1, 12, 6, 6])\n",
      "blocks.11.attn.hook_pattern torch.Size([1, 12, 6, 6])\n",
      "blocks.11.attn.hook_z torch.Size([1, 6, 12, 64])\n",
      "blocks.11.hook_attn_out torch.Size([1, 6, 768])\n",
      "blocks.11.hook_resid_mid torch.Size([1, 6, 768])\n",
      "blocks.11.ln2.hook_scale torch.Size([1, 6, 1])\n",
      "blocks.11.ln2.hook_normalized torch.Size([1, 6, 768])\n",
      "blocks.11.mlp.hook_pre torch.Size([1, 6, 3072])\n",
      "blocks.11.mlp.hook_post torch.Size([1, 6, 3072])\n",
      "blocks.11.hook_mlp_out torch.Size([1, 6, 768])\n",
      "blocks.11.hook_resid_post torch.Size([1, 6, 768])\n",
      "ln_final.hook_scale torch.Size([1, 6, 1])\n",
      "ln_final.hook_normalized torch.Size([1, 6, 768])\n"
     ]
    }
   ],
   "source": [
    "# Get internal activations\n",
    "logits, cache = model.run_with_cache(\"Famous computer scientist Alan\")\n",
    "\n",
    "for key, value in cache.items():\n",
    "    print(key, value.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "arena",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
